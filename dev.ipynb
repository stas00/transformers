{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, f\"{os.getcwd()}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tokenization_fsmt import FSMTTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fairseq tokenizer\n",
    "\n",
    "hub_utils.py:\n",
    "        \n",
    "    def encode(self, sentence: str) -> torch.LongTensor:\n",
    "        sentence = self.tokenize(sentence)\n",
    "        sentence = self.apply_bpe(sentence)\n",
    "        return self.binarize(sentence)\n",
    "\n",
    "    def decode(self, tokens: torch.LongTensor) -> str:\n",
    "        sentence = self.string(tokens)\n",
    "        sentence = self.remove_bpe(sentence)\n",
    "        return self.detokenize(sentence)\n",
    "\n",
    "    def tokenize(self, sentence: str) -> str:\n",
    "        if self.tokenizer is not None:\n",
    "            sentence = self.tokenizer.encode(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def detokenize(self, sentence: str) -> str:\n",
    "        if self.tokenizer is not None:\n",
    "            sentence = self.tokenizer.decode(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def apply_bpe(self, sentence: str) -> str:\n",
    "        if self.bpe is not None:\n",
    "            sentence = self.bpe.encode(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def remove_bpe(self, sentence: str) -> str:\n",
    "        if self.bpe is not None:\n",
    "            sentence = self.bpe.decode(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def binarize(self, sentence: str) -> torch.LongTensor:\n",
    "        return self.src_dict.encode_line(sentence, add_if_not_exist=False).long()\n",
    "\n",
    "    def string(self, tokens: torch.LongTensor) -> str:\n",
    "        return self.tgt_dict.string(tokens)       \n",
    "        \n",
    "1. tokenize using tokenizer.perl from mosesdecoder https://github.com/moses-smt/mosesdecoder\n",
    "\n",
    "\n",
    "\n",
    "2. apply_bpe.py script using the wmt14.en-fr.fconv-cuda/bpecodes file\n",
    "https://github.com/rsennrich/subword-nmt/blob/master/subword_nmt/apply_bpe.py\n",
    "\n",
    "fairseq/data/encoders/fastbpe.py uses fastBPE\n",
    "loads \"model/bpecodes\" file\n",
    "\n",
    "\n",
    "3. binarize\n",
    "\n",
    "somehow need to re-use bpe codes:https://github.com/facebookresearch/XLM#download--preprocess-data\n",
    "\n",
    "> If you want to use our pretrained models, you need to have an exactly identical vocabulary. Since small differences can happen during preprocessing, we recommend that you use our BPE codes and vocabulary (although you should get something almost identical if you learn the codes and compute the vocabulary yourself).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"Machine Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/wmt19.ru-en.ensemble/bpecodes'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<fastBPE.fastBPE object at 0x7fbd115b2b30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Mach@@ ine L@@ ear@@ ning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Machine Learning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastBPE\n",
    "import fairseq\n",
    "bpe_codes = 'data/wmt19.ru-en.ensemble/bpecodes'\n",
    "codes = fairseq.file_utils.cached_path(bpe_codes)\n",
    "codes\n",
    "bpe = fastBPE.fastBPE(codes)\n",
    "bpe\n",
    "bpe_symbol = \"@@ \"\n",
    "def encode(x: str) -> str: return bpe.apply([x])[0]\n",
    "def decode(x: str) -> str: return (x + ' ').replace(bpe_symbol, '').rstrip()\n",
    "encoded = encode(\"Machine Learning\")\n",
    "encoded\n",
    "decoded = decode(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine</w>', 'Le', 'arning</w>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['M@@', 'a@@', 'c@@', 'h@@', 'i@@', 'n@@', 'e', 'L@@', 'e@@', 'a@@', 'r@@', 'n@@', 'i@@', 'n@@', 'g']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import XLMTokenizer, CTRLTokenizer\n",
    "tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "tokenizer.tokenize(line)\n",
    "tokenizer = CTRLTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "tokenizer.tokenize(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Model name 'data/wmt19.ru-en.ensemble/' was not found in tokenizers model name list (fsmt-wmt19-ru-en). We assumed 'data/wmt19.ru-en.ensemble/' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.json', 'merges.txt'] but couldn't find such vocabulary files at this path or url.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-104dd16c588f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFSMTTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/wmt19.ru-en.ensemble/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/nvme1/code/huggingface/transformers-fair-wmt/src/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \"\"\"\n\u001b[0;32m-> 1423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme1/code/huggingface/transformers-fair-wmt/src/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1527\u001b[0m                     \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_files_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 )\n\u001b[1;32m   1531\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: Model name 'data/wmt19.ru-en.ensemble/' was not found in tokenizers model name list (fsmt-wmt19-ru-en). We assumed 'data/wmt19.ru-en.ensemble/' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.json', 'merges.txt'] but couldn't find such vocabulary files at this path or url."
     ]
    }
   ],
   "source": [
    "#tokenizer = FSMTTokenizer.from_pretrained('data/wmt19.ru-en.ensemble/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nvme1/code/huggingface/transformers-fair-wmt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect, os\n",
    "os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore checkpoint's contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "path = \"/code/huggingface/transformers-fair-wmt\"\n",
    "chkpt1_path = path + \"/data/wmt19.ru-en.ensemble/model4.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load(chkpt1_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['args', 'model', 'optimizer_history', 'last_optimizer_state', 'extra_state'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adam_betas': '(0.9, 0.98)',\n",
      " 'adam_eps': 1e-08,\n",
      " 'adaptive_input': False,\n",
      " 'adaptive_softmax_cutoff': None,\n",
      " 'adaptive_softmax_dropout': 0,\n",
      " 'arch': 'transformer_wmt_en_de_big',\n",
      " 'attention_dropout': 0.1,\n",
      " 'bucket_cap_mb': 25,\n",
      " 'clip_norm': 0.0,\n",
      " 'cpu': False,\n",
      " 'criterion': 'label_smoothed_cross_entropy',\n",
      " 'data': ['/private/home/edunov/wmt19/data/old/enru',\n",
      "          '/private/home/edunov/wmt19/data/old/enru',\n",
      "          '/private/home/edunov/wmt19/data/finetune/ncru/',\n",
      "          '/private/home/edunov/wmt19/data/temp/enru'],\n",
      " 'ddp_backend': 'c10d',\n",
      " 'decoder_attention_heads': 16,\n",
      " 'decoder_embed_dim': 1024,\n",
      " 'decoder_embed_path': None,\n",
      " 'decoder_ffn_embed_dim': 4096,\n",
      " 'decoder_input_dim': 1024,\n",
      " 'decoder_layers': 6,\n",
      " 'decoder_learned_pos': False,\n",
      " 'decoder_normalize_before': False,\n",
      " 'decoder_output_dim': 1024,\n",
      " 'device_id': 0,\n",
      " 'distributed_backend': 'nccl',\n",
      " 'distributed_init_method': 'tcp://localhost:17185',\n",
      " 'distributed_port': -1,\n",
      " 'distributed_rank': 0,\n",
      " 'distributed_world_size': 2,\n",
      " 'dropout': 0.2,\n",
      " 'encoder_attention_heads': 16,\n",
      " 'encoder_embed_dim': 1024,\n",
      " 'encoder_embed_path': None,\n",
      " 'encoder_ffn_embed_dim': 8192,\n",
      " 'encoder_layers': 6,\n",
      " 'encoder_learned_pos': False,\n",
      " 'encoder_normalize_before': False,\n",
      " 'fix_batches_to_gpus': False,\n",
      " 'fp16': True,\n",
      " 'fp16_init_scale': 128,\n",
      " 'fp16_scale_tolerance': 0.0,\n",
      " 'fp16_scale_window': None,\n",
      " 'keep_interval_updates': -1,\n",
      " 'keep_last_epochs': -1,\n",
      " 'label_smoothing': 0.1,\n",
      " 'lazy_load': False,\n",
      " 'left_pad_source': True,\n",
      " 'left_pad_target': False,\n",
      " 'log_format': 'simple',\n",
      " 'log_interval': 100,\n",
      " 'lr': [0.0007],\n",
      " 'lr_scheduler': 'inverse_sqrt',\n",
      " 'lr_shrink': 0.1,\n",
      " 'max_epoch': 0,\n",
      " 'max_sentences': None,\n",
      " 'max_sentences_valid': None,\n",
      " 'max_source_positions': 1024,\n",
      " 'max_target_positions': 1024,\n",
      " 'max_tokens': 3584,\n",
      " 'max_update': 203000,\n",
      " 'memory_efficient_fp16': False,\n",
      " 'min_loss_scale': 0.0001,\n",
      " 'min_lr': 1e-09,\n",
      " 'momentum': 0.99,\n",
      " 'no_epoch_checkpoints': False,\n",
      " 'no_progress_bar': True,\n",
      " 'no_save': False,\n",
      " 'no_token_positional_embeddings': False,\n",
      " 'num_workers': 0,\n",
      " 'optimizer': 'adam',\n",
      " 'optimizer_overrides': '{}',\n",
      " 'raw_text': False,\n",
      " 'relu_dropout': 0.0,\n",
      " 'reset_lr_scheduler': False,\n",
      " 'reset_optimizer': False,\n",
      " 'restore_file': 'checkpoint_last.pt',\n",
      " 'save_dir': '/checkpoint/edunov/20190403/wmt19ru2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed2_lbsm0.1_size_sa0_upsample4/finetune/',\n",
      " 'save_interval': 1,\n",
      " 'save_interval_updates': 200,\n",
      " 'seed': 2,\n",
      " 'sentence_avg': False,\n",
      " 'share_all_embeddings': False,\n",
      " 'share_decoder_input_output_embed': True,\n",
      " 'skip_invalid_size_inputs_valid_test': False,\n",
      " 'source_lang': 'ru',\n",
      " 'target_lang': 'en',\n",
      " 'task': 'translation',\n",
      " 'tensorboard_logdir': '',\n",
      " 'threshold_loss_scale': None,\n",
      " 'train_subset': 'train',\n",
      " 'update_freq': [1],\n",
      " 'upsample_primary': 4,\n",
      " 'user_dir': None,\n",
      " 'valid_subset': 'valid',\n",
      " 'validate_interval': 1,\n",
      " 'warmup_init_lr': 1e-07,\n",
      " 'warmup_updates': 4000,\n",
      " 'weight_decay': 0.0}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(chkpt[\"args\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'criterion_name': 'LabelSmoothedCrossEntropyCriterion',\n",
      "  'lr_scheduler_state': {'best': 3.449914911560068},\n",
      "  'num_updates': 200000,\n",
      "  'optimizer_name': 'FP16Optimizer'},\n",
      " {'criterion_name': 'LabelSmoothedCrossEntropyCriterion',\n",
      "  'lr_scheduler_state': {'best': 3.449914911560068},\n",
      "  'num_updates': 201600,\n",
      "  'optimizer_name': 'FP16Optimizer'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(chkpt[\"optimizer_history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('state',\n",
      "              OrderedDict([(139681734876832,\n",
      "                            OrderedDict([('step', 201600),\n",
      "                                         ('exp_avg',\n",
      "                                          tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3744e-04,\n",
      "        -1.2752e-04, -2.1968e-05])),\n",
      "                                         ('exp_avg_sq',\n",
      "                                          tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.6497e-07, 5.2216e-07,\n",
      "        5.1033e-07]))]))])),\n",
      "             ('param_groups',\n",
      "              [OrderedDict([('lr', 9.860132971832693e-05),\n",
      "                            ('betas', (0.9, 0.98)),\n",
      "                            ('eps', 1e-08),\n",
      "                            ('weight_decay', 0.0),\n",
      "                            ('amsgrad', False),\n",
      "                            ('params', [139681734876832])])]),\n",
      "             ('loss_scale', 1.0)])\n"
     ]
    }
   ],
   "source": [
    "pprint(chkpt[\"last_optimizer_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best': 2.870054022029137,\n",
      " 'train_iterator': {'epoch': 13, 'iterations_in_epoch': 1601},\n",
      " 'train_meters': OrderedDict([('train_loss',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad150>),\n",
      "                              ('train_nll_loss',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad310>),\n",
      "                              ('valid_loss',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad390>),\n",
      "                              ('valid_nll_loss',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad410>),\n",
      "                              ('wps',\n",
      "                               <fairseq.logging.meters.TimeMeter object at 0x7fbd014ad490>),\n",
      "                              ('ups',\n",
      "                               <fairseq.logging.meters.TimeMeter object at 0x7fbd014ad5d0>),\n",
      "                              ('wpb',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad650>),\n",
      "                              ('bsz',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad6d0>),\n",
      "                              ('gnorm',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad750>),\n",
      "                              ('clip',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad7d0>),\n",
      "                              ('oom',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad850>),\n",
      "                              ('loss_scale',\n",
      "                               <fairseq.logging.meters.AverageMeter object at 0x7fbd014ad890>),\n",
      "                              ('wall',\n",
      "                               <fairseq.logging.meters.TimeMeter object at 0x7fbd014ad910>),\n",
      "                              ('train_wall',\n",
      "                               <fairseq.logging.meters.StopwatchMeter object at 0x7fbd014ad990>)]),\n",
      " 'val_loss': 2.870054022029137}\n"
     ]
    }
   ],
   "source": [
    "pprint(chkpt[\"extra_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model via fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq import hub_utils\n",
    "checkpoint_file = 'model1.pt:model2.pt:model3.pt:model4.pt'\n",
    "model_name_or_path = 'transformer.wmt19.ru-en'\n",
    "data_name_or_path = '.'\n",
    "cls = fairseq.model_parallel.models.transformer.ModelParallelTransformerModel\n",
    "models = cls.hub_models()\n",
    "kwargs = {'bpe': 'fastbpe', 'tokenizer': 'moses'}\n",
    "x = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=models,\n",
    "            **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_dropout': 0.0,\n",
      " 'activation_fn': 'relu',\n",
      " 'adam_betas': '(0.9, 0.98)',\n",
      " 'adam_eps': 1e-08,\n",
      " 'adaptive_input': False,\n",
      " 'adaptive_softmax_cutoff': None,\n",
      " 'adaptive_softmax_dropout': 0,\n",
      " 'arch': 'transformer_wmt_en_de_big',\n",
      " 'attention_dropout': 0.1,\n",
      " 'bpe': 'fastbpe',\n",
      " 'bpe_codes': '/home/stas/.cache/torch/pytorch_fairseq/1f635f61a93197b2be015bcdc60f47829db1172b5b81547d72b7b28235b28fa9.5e1a2ea19b51d6733a96ed885e05dc2d3d1e3cb3573b9e62ee7acfb0454ee976/bpecodes',\n",
      " 'bucket_cap_mb': 25,\n",
      " 'clip_norm': 0.0,\n",
      " 'cpu': False,\n",
      " 'criterion': 'label_smoothed_cross_entropy',\n",
      " 'cross_self_attention': False,\n",
      " 'data': '/home/stas/.cache/torch/pytorch_fairseq/1f635f61a93197b2be015bcdc60f47829db1172b5b81547d72b7b28235b28fa9.5e1a2ea19b51d6733a96ed885e05dc2d3d1e3cb3573b9e62ee7acfb0454ee976',\n",
      " 'ddp_backend': 'c10d',\n",
      " 'decoder_attention_heads': 16,\n",
      " 'decoder_embed_dim': 1024,\n",
      " 'decoder_embed_path': None,\n",
      " 'decoder_ffn_embed_dim': 4096,\n",
      " 'decoder_input_dim': 1024,\n",
      " 'decoder_layerdrop': 0,\n",
      " 'decoder_layers': 6,\n",
      " 'decoder_layers_to_keep': None,\n",
      " 'decoder_learned_pos': False,\n",
      " 'decoder_normalize_before': False,\n",
      " 'decoder_output_dim': 1024,\n",
      " 'device_id': 0,\n",
      " 'distributed_backend': 'nccl',\n",
      " 'distributed_init_method': 'tcp://localhost:17185',\n",
      " 'distributed_port': -1,\n",
      " 'distributed_rank': 0,\n",
      " 'distributed_world_size': 2,\n",
      " 'dropout': 0.2,\n",
      " 'encoder_attention_heads': 16,\n",
      " 'encoder_embed_dim': 1024,\n",
      " 'encoder_embed_path': None,\n",
      " 'encoder_ffn_embed_dim': 8192,\n",
      " 'encoder_layerdrop': 0,\n",
      " 'encoder_layers': 6,\n",
      " 'encoder_layers_to_keep': None,\n",
      " 'encoder_learned_pos': False,\n",
      " 'encoder_normalize_before': False,\n",
      " 'eval_bleu_detok': 'space',\n",
      " 'eval_bleu_remove_bpe': None,\n",
      " 'eval_tokenized_bleu': False,\n",
      " 'fix_batches_to_gpus': False,\n",
      " 'fp16': True,\n",
      " 'fp16_init_scale': 128,\n",
      " 'fp16_scale_tolerance': 0.0,\n",
      " 'fp16_scale_window': None,\n",
      " 'keep_interval_updates': -1,\n",
      " 'keep_last_epochs': -1,\n",
      " 'label_smoothing': 0.1,\n",
      " 'layernorm_embedding': False,\n",
      " 'lazy_load': False,\n",
      " 'left_pad_source': True,\n",
      " 'left_pad_target': False,\n",
      " 'log_format': 'simple',\n",
      " 'log_interval': 100,\n",
      " 'lr': [0.0007],\n",
      " 'lr_scheduler': 'inverse_sqrt',\n",
      " 'lr_shrink': 0.1,\n",
      " 'max_epoch': 0,\n",
      " 'max_sentences': None,\n",
      " 'max_sentences_valid': None,\n",
      " 'max_source_positions': 1024,\n",
      " 'max_target_positions': 1024,\n",
      " 'max_tokens': 3584,\n",
      " 'max_update': 203000,\n",
      " 'memory_efficient_fp16': False,\n",
      " 'min_loss_scale': 0.0001,\n",
      " 'min_lr': 1e-09,\n",
      " 'momentum': 0.99,\n",
      " 'moses_no_dash_splits': False,\n",
      " 'moses_no_escape': False,\n",
      " 'no_cross_attention': False,\n",
      " 'no_epoch_checkpoints': False,\n",
      " 'no_progress_bar': True,\n",
      " 'no_save': False,\n",
      " 'no_scale_embedding': False,\n",
      " 'no_token_positional_embeddings': False,\n",
      " 'num_batch_buckets': 0,\n",
      " 'num_workers': 0,\n",
      " 'optimizer': 'adam',\n",
      " 'optimizer_overrides': '{}',\n",
      " 'quant_noise_pq': 0,\n",
      " 'quant_noise_pq_block_size': 8,\n",
      " 'quant_noise_scalar': 0,\n",
      " 'raw_text': False,\n",
      " 'relu_dropout': 0.0,\n",
      " 'reset_lr_scheduler': False,\n",
      " 'reset_optimizer': False,\n",
      " 'restore_file': 'checkpoint_last.pt',\n",
      " 'save_dir': '/checkpoint/edunov/20190403/wmt19ru2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed2_lbsm0.1_size_sa0_upsample4/finetune/',\n",
      " 'save_interval': 1,\n",
      " 'save_interval_updates': 200,\n",
      " 'seed': 2,\n",
      " 'sentence_avg': False,\n",
      " 'share_all_embeddings': False,\n",
      " 'share_decoder_input_output_embed': True,\n",
      " 'skip_invalid_size_inputs_valid_test': False,\n",
      " 'source_lang': 'ru',\n",
      " 'target_lang': 'en',\n",
      " 'task': 'translation',\n",
      " 'tensorboard_logdir': '',\n",
      " 'threshold_loss_scale': None,\n",
      " 'tie_adaptive_weights': False,\n",
      " 'tokenizer': 'moses',\n",
      " 'train_subset': 'train',\n",
      " 'truncate_source': False,\n",
      " 'update_freq': [1],\n",
      " 'upsample_primary': 4,\n",
      " 'use_old_adam': False,\n",
      " 'user_dir': None,\n",
      " 'valid_subset': 'valid',\n",
      " 'validate_interval': 1,\n",
      " 'warmup_init_lr': 1e-07,\n",
      " 'warmup_updates': 4000,\n",
      " 'weight_decay': 0.0}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(x[\"args\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fairseq.tasks.translation.TranslationTask object at 0x7fbd014b7490>\n"
     ]
    }
   ],
   "source": [
    "pprint(x[\"task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31232, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31640, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=1024, out_features=31640, bias=False)\n",
      "  )\n",
      "),\n",
      " TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31232, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31640, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=1024, out_features=31640, bias=False)\n",
      "  )\n",
      "),\n",
      " TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31232, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31640, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=1024, out_features=31640, bias=False)\n",
      "  )\n",
      "),\n",
      " TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31232, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
      "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(31640, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=1024, out_features=31640, bias=False)\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "pprint(x[\"models\"]) # 4 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  -   !'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = x[\"args\"] # loaded from the checkpoint earlier\n",
    "from fairseq.data.encoders.moses_tokenizer import MosesTokenizer\n",
    "#from argparse import Namespace\n",
    "#args = argparse.Namespace(moses_source_lang='ru_RU', moses_target_lang='en_XX')\n",
    "# fairseq.data.encoders.moses_tokenizer.MosesTokenizer\n",
    "sentence = \"  -  !\"\n",
    "tokenizer = MosesTokenizer(args)\n",
    "sentence = tokenizer.encode(sentence)\n",
    "sentence\n",
    "\n",
    "# well it mainly just adds whitespace where needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@ @@   -   !'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairseq.data.encoders.fastbpe import fastBPE\n",
    "bpe = fastBPE(args)\n",
    "sentence = bpe.encode(sentence)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize (bytecodes into numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  648, 13440,    97,  3618,    25,    74, 22548,   384,     2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%pixie_debugger -b /mnt/nvme1/code/github/00nlp/fairseq/fairseq/data/dictionary.py:30\n",
    "\n",
    "from fairseq.data.dictionary import Dictionary\n",
    "\n",
    "filename = '/home/stas/.cache/torch/pytorch_fairseq/1f635f61a93197b2be015bcdc60f47829db1172b5b81547d72b7b28235b28fa9.5e1a2ea19b51d6733a96ed885e05dc2d3d1e3cb3573b9e62ee7acfb0454ee976/dict.ru.txt'\n",
    "#cls = fairseq.tasks.translation.TranslationTask\n",
    "\n",
    "#src_dict = Dictionary(args)\n",
    "src_dict = Dictionary.load(filename)\n",
    "#dir(src_dict)\n",
    "\n",
    "# self.binarize(sentence) equivalent\n",
    "src_dict.encode_line(sentence, add_if_not_exist=False).long()\n",
    "# setup_task loads both dicts\n",
    "\n",
    "# this looks up the tokenized bpe strings in the dict and replaces them with the dict indices\n",
    "src_dict.index(\"@@\")\n",
    "src_dict.index(\"@@\") # unk (this token doesn't exist in the dict)\n",
    "\n",
    "# the vocab is this dict:\n",
    "# src_dict.indices\n",
    "# can be fed directly to json.dumps => vocab.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['<s>', '<pad>', '</s>', '<unk>', ',', '.', '', '', '', ')', ':', '', '', '/', '@-@', '(', '&quot;', '', '', '', '', '', '', '', ';', '-', '', '', '', '', '', '', '*', '', '1', '', '', '', '&gt;', '', '', '&lt;', '2', '', '', '@@', '3', '', '', '', '10', '', '', '', '4', '', '', '', '', '', '', '', '', '5', '', '', '', '', '', '', '', '#', '', '', '', '', '12', '', '', '', '', '', '6', '', '00', '', '', '', '', '', '', '11', '', '', '7', '', '', '', '', '', '?', '15', 'a', '', '', '', '', '', '', '', '8', '2@@', '', '@@', '', '9', '', '', '', '', '', 'A', '', '', '20', '@@', '', '14', '', '3@@', '', '', '', '', '', '@@', '', '13', '&#93;', '', '', '16', '', '30', '@@', '.@@', '@@', '', '', '@@', '', '', '', '18', '', '', '', '', '', '@@', '', '', '@@', '', '+', '', '&#91;', '', '', '', '17', '', '', '', '', '25', '', '', '', '', '4@@', '', 'b', '', 'S@@', '22', '', '19', '21', '', '', '', '', '', '', '2009', '', '', '', '', '', '', '', '%', '', '', '', '', '', '5@@', '', '', '23', '', '@@', 'P@@', '', '', '', '@@', '2008', '', '', '', '', '@@', '2010', '9@@', '', '', '', '@@', '', '', '--', '@@', 'C', '', '6@@', '@@', '', '@@', '', '', '', '24', '', '@@', '', '', 'http', 'C@@', '=', '@@', '', 'T@@', '2011', '7@@', '', '@@', 'on', '', '', '', '2012', '', '@@', '', 'is', '', '', '', '@@', '', '', '', '2006', '2007', '@@', '@@', '@@', '', '@@', '', '26', '', '31', '', '', '', '@@', '2016', '', '', '', '', '27', '2005', '', '', '', '28', '@@', '', '@@', '', '', '', '', '', '', '', 'D@@', '', '', '', '@@', '@@', '', '', '', '@@', '2013', 'm@@', '@@', '@@', '@@', '', '', '8@@', '', '', '', 'E@@', '', '01', '', '19@@', '', 'M@@', '', '', '...', '', '', '', '', '', 'd@@', '@@', '', '@@', '', '', '@@', '', '29', '', '', '@@', '@@', '', '', '', '', 'p@@', '50', '', '', '@@', '@@', 'c@@', 'A@@', '', '', '04', '', '', '', 'AM', '', '_', '@@', '', '!', '@@', '', '', '@@', '', '', '02', '', '@@', '', 'B@@', '', '', 'H@@', '05', 'i', '', '06', '', 'b@@', '', '', '', '', '', '@@', '', '', '03', '', 's@@', '', '', '', '', '@@', '', '2004', '0@@', '', '', '@@', '', '', '@@', 'f@@', '@@', 'G@@', 'S', 'PM', '', '', '', '', '@@', '@@', '', '@@', 'd', 'L@@', '', '', '', '@@', 'i@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '40', 'The', '', '', '', '07', '@@', 'E', 'c', '', '', '', '', '', '@@', '', '', 'k@@', '', '08', '', '@@', '', '09', '', '2014', '', '@@', '', '', '', 'I', 'R@@', '', '', '', '', '', '', '2000', '', '000', '', '', 'e', '', '', 'a@@', '', '', '', '2003', '', 'g@@', '@@', '', '', '1@@', '', '', '', '', '', '', '', 't@@', '', 'e@@', '', '', '', '', '', 'l@@', '', '', '', '', '', '2015', '', '@@', '', '', '', '@@', '@@', '', '', '', 'F@@', '', '', '', '2002', '', '', '', '', '', '', '0', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', 'y@@', '', '', '2001', '', '', '', 'O@@', '@@', '', '', '&apos;', '18@@', '', 's', '', '', 'n@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '.', '', 'I@@', '10@@', '', '@@', '.', '', '', '35', '', '', '@@', '', '', 'W@@', '', '', '', '', '@@', '@@', '.', '', '1998', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '49', '@@', 'II', '', '', '1999', '', '@@', 'May', '33', '32', '@@', '', 'r@@', '', '', '@@', '', '', '', '1.@@', '48', '', '2.@@', '', '', '', '', 'o', '1995', '@@', 'V@@', '', '', '@@', '51', '@@', '', '', '', '', '', '', '45', '', '14@@', '', '', '', '', '', 'h@@', '@@', '', '20@@', '', '', '', '', '', '', '', '', '', '', '', 'N@@', '16@@', '', '34', '@@', '', '@@', '', '', 'Posted', '1997', '', '', '', '1994', '@@', '', '', '36', '', '', '', '', '', '', '', '', '', '17@@', '@@', '', '', '', 't', '@@', '55', '', '37', '', '52', '', '', '@@', '', '', '@@', '@@', 'er@@', '', '1996', '60', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', 'www.@@', '', '', '58', '@@', '', '', '', 'v@@', '', '', '38', '', 'K@@', '', 'the', '', '', '', '', '15@@', '', '.', '', '', '53', '39', '@@', '3.@@', '', '44', '', '@@', '', '', '57', '', 'u@@', '', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', 'Reply', '', '41', '@@', '59', '', '@@', '', '@@', '', '', '', '47', 'time', '@@', 'ar@@', '', '54', '', '@@', '', '', '42', '', '', '', '', '', 'L.@@', 'now', '56', '', '', 'm', '', '', '46', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '', 'al@@', '@@', '', '', '', '', '43', '@@', '@@', '', '4.@@', '@@', '', 'w@@', '100', 'en@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '13@@', '', '', '@@', '', '', '', 'es', '', '@@', '', '', '', '', '', 'o@@', '', '', '', '', '', '@@', '', '', 'It', 'an@@', '', 'B', '', 'in', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', 'in@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', 'currently', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', 'D', '', '@', '', '', '', '5.@@', '', '', '', '', '', '', '', '', '', '', '', '1993', 'ad@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '', 'z@@', '@@', '', '', '', '', '', '', '63', '', 'to', '', '', '', '@@', 'U@@', '', '', '', '', 'it@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '2017', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '', 'X@@', '@@', '64', '', '', '', '', '65', '', '', '', '', '@@', '', '', '', '', '61', '', '', '', '', '', '@@', '@@', '', 'of', '', '', '', '', 'or@@', '', '', '@@', '', '6.@@', '', '', '@@', '@@', '', '', 'g', '', '', 'er', '', '', 'III', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '.1', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', 'y', '', '', '', '', '', '@@', '', '', '@@', '', 're@@', '', '', '', '', '', '.com', 'f', '', '', '28@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', 'P', '62', '', '@@', '', '', 'am', 'st@@', '', '', '', '.', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '29@@', '', '', '@@', '', '', '', '', '', '', '', '', 'j@@', '', '@@', '27@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', 'p', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '66', '', '', '', '', '', '@@', '@@', '', '', 'on@@', '', '', '', '70', '', '', '', '', '', 'at@@', '@@', '', '', '', 'R', '@@', '', '@@', '', '', '', '', '@@', '', '', '80', '', '', '@@', '', 'and', '', 'x@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '-@@', '', '', '', '', '', '', '', '@@', '', '', '', '', '', 'el@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', 'x', '', '', '', '', '', '', '67', '', '', '', '', '', '', '', '', '', '', '@@', '90', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '12@@', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', 'k', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '', '', 'ic@@', '', '@@', '', '', '&amp;', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', 'was', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', 'am@@', '@@', 'ch@@', '@@', '@@', 'l', '', '', 'et@@', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '68', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '@@', 'F', '', '', '@@', '', '', '', '', '', '', '', '', '@@', 'de', 'N', '', '', '', '', '', '', '', '', '@@', '', 'an', '', '', '@@', '', '', '', '1992', 'as@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '69', '75', '@@', '', '', '', '', '@@', '', '7.@@', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '', 'ed', '', '', '', '', '@@', '', '', '', 'h', '.ru', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '', 'Add.@@', '', '@@', '', '', 'J@@', '', '', 'un@@', '', '', '', '@@', '', '@@', '', '', '25@@', '', '', '', '@@', '@@', '', '@@', 'en', '', 'not', 'n', '', '', '@@', '', '', '', '', '', '', '', '', 'IV', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', 'te@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '', '', 'L', '@@', '', '', '', '', '', '', '', '200', '@@', '', '', '', '', 'es@@', 'ac@@', '', 'al', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', 'G', '', '', '', '77', '', '@@', '', '', '', '', '', '', 'di@@', '', '', '@@', '', '', '8.@@', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', '1990', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'pm', '', '00@@', '@@', '', '@@', '', '@@', 'T', '@@', '', '', 'TRANS', '@@', '', '', '@@', '', '', '', '', '', '@@', '', 'V', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '@@', 'ro@@', '@@', '', '', '', '', '@@', '', '', 'av@@', '', '@@', '1991', '', '', '', '@@', '@@', 'le@@', '', 'URL', '', '@@', '@@', '', 'ii', '', '', '', '', '', '', '', '', '', 'v', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', 'ri@@', 'im@@', '', '', '', '', '', '', '', '', '', '', 'ol@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '73', '', '500', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', 'M', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '$', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', 'at', '', 'this', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '', 'Add.1', '', '', '', 'Joined', '', '', '@@', '', '@@', '', '', '30@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', 'il@@', '@@', '', '', 'ing', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '72', '', '', '@@', '', 'is@@', '@@', '', '', '', 'O', '', '', 'th@@', '@@', '@@', '@@', '@@', 'us@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', 'ec@@', '@@', '', '@@', 'Z@@', '', '@@', '', 'H', '@@', '', '', 'ur@@', '@@', '', '', '@@', '@@', '', 'os@@', '@@', '', '', '', '', '', '', '', 'ar', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '9.@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '0,@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ECE', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '', 'it', '@@', '', '300', '', '', 'um@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', 'u', '@@', '', '', '@@', '', '', '', '@@', 'de@@', '', '', '', '71', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', 'ti@@', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '74', 'W', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '1.', '@@', '', '', '', '', '@@', '', '', '', '', '85', '', '', 'Windows', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', 'day', '', '', '@@', '@@', '', '', '', '.html', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', 'ab@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', 'ap@@', '@@', '@@', '', '', '95', '', '', '@@', '', '', '', 'em@@', '', '@@', '@@', '', '@@', 'WP.@@', '', 'ent@@', '', '', '', '', '@@', '', '', '', '', '..', '', '@@', '', '76', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '96', '', '', '23@@', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '.0@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', 'GR@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '87', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '99', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '78', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '.', '@@', '', '', '', 'server', '@@', '@@', '@@', '', '.org', '', '', '', '@@', '', 'r', '', '', '@@', '', '', '', '', '24@@', '@@', '@@', '@@', '', '', 'found', '@@', '@@', '', '', 'vi@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '', 'z', 'ir@@', '', '', '', '@@', '', 'li@@', '', '@@', '', '', '', '', '', '', '@@', 'ot@@', '@@', '', 'by', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', 'om@@', '@@', '@@', '', '86', '@@', '', '', '', '@@', '', '', '', '', '@@', '83', '@@', '', '@@', '', '', '98', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '93', '', 'ag@@', '', '', '@@', '@@', '', '', '', '88', '', '', '', '94', '', 'ru', '@@', '82', '', '@@', '81', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', 'requested', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '79', '@@', '', '', '@@', 'et', '', '@@', '26@@', '@@', '', '', '', '', '', '@@', '', '', '', '', 'Y@@', '@@', '', '\\\\', 'In@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '97', '', '', '', '', '@@', '', '@@', 'VI', '', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', 'ul@@', '', '', '', '', '', '', '', '', '', '', 'X', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '', 'eb@@', '', '', '', '', '', '@@', '84', '@@', '', '', '', '', '92', '@@', '91', '', '', '', '', '', '', 'as', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '12.@@', 'tion', '@@', '', '', '@@', 'us', '@@', 'sp@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '', 'w', '@@', '@@', '', '', '', 'ed@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '.', '', '', 'ing@@', '@@', '@@', '', '', '', '', '', '', '@@', '', 'forum', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', 'ay@@', 'St@@', '', '@@', '@@', '', '89', '@@', '@@', '', '', '', '', '', '', '', '@@', '2.', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', 'IN@@', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '50@@', '@@', '', '', 'IS@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '400', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', 'C.@@', '', '', '@@', 'ut@@', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', 'AC.@@', '', '', '@@', '', 'sh@@', '', '', '@@', '', '', 'are', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '11.@@', '', '@@', '', '', '', '', '@@', '', '@@', '', 'ru@@', '', '@@', '', 'or', '', '', '', '', '', '', '600', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', 'op@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', 'times', '', '', '', 'ak@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', 'WP.29', '', '', '', '@@', '', '', '', '', '', '@@', '', '@@', 'ia', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', 'iii', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '.', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', 'C.3', '', '', '', '', '', 'ts', '', 'end@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '10.@@', '@@', 'A.', '', '@@', '@@', '', '', '', '', '', '@@', '', '40@@', '', '@@', '@@', '.2', '', '', '', '@@', '', '@@', 'oc@@', '', '', '', '', 'I.', '@@', '', '', '', '', 'ou@@', '', '', '', 'CC@@', 'co@@', '@@', '', '', '', '', '', '@@', '', '', 'ation', '@@', '', '', '', '@@', '', '', 'November', '', '', '', '', '', '@@', '@@', '@@', 'Q@@', '', '', '', 'ov@@', '', '@@', '', '', '@@', '', '', '@@', '', 'ig@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', 'ine', '', 'ter', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', 'lo@@', '@@', '', '', 'Ch@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '1,@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', 'CO@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', 'CE@@', '', '@@', '', '', '@@', '', '', '', '@@', '60@@', '', '@@', 'Th@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '', 'and@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', 'VII', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', 'pro@@', '@@', '', '', '', '', '', '', '', '@@', '', '', 'B.', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', 'ex@@', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '', 'KASE', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '3.', '', '@@', '', '', '', '', '', '', '', '', '', '', '', 'for', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', 'per@@', '6,@@', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', 'ted', 'az@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', 'e.@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '800', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '5,@@', '@@', '150', '', '.', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '201@@', '', '', '', '@@', '@@', '', '', '@@', 'si@@', '', '', '', '@@', '@@', '@@', '', '', '', 'Pro@@', '@@', '@@', '', '@@', '', '120', '', '', 'June', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', 'wipe', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '4,@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '', '200@@', '@@', '', '', '', '', 'You', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '90@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', 'XXI', '@@', '@@', '@@', '@@', '', '', '', '@@', '', 'se@@', '', '@@', '', '', '@@', '@@', '', '', 'tr@@', '', '', '@@', '', '', 'id@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '@@', 'ver@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '.', '', 'ad', '', '', '@@', '', '', '@@', '', '', '', '@@', '', 'un.org', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', 'C.1', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', 'Rev.1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '..', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', 'December', '', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', 'UN@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', 'P.@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', 'K', '', '', '', '@@', 'le', '', '', '', '', 'pl@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '4.', '', '', '@@', '', '@@', 'html', '@@', '@@', '', '@@', '@@', '@@', '', '', 'el', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', 'CN.@@', '@@', '', '', '', '', '@@', '33@@', '', '', '', '', '@@', '@@', '@@', 'EN@@', '', '@@', '@@', '', 'Re@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', 'CN.4', '', '', '', '', '', '', '@@', '', '', '@@', 'ra@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '1989', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '70@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', 'D.', '', '', 'C.2', '', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', 'ER@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '', 'September', '', '', '', '', '', '@@', '@@', '', '80@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', 'August', '', 'ne@@', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '700', '', 'pe@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '', 'ated', '', '@@', '', '@@', 'od@@', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '2.1', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', 'October', '', '', '', '', '@@', '', 'US@@', '', '', '', '', '', '', '@@', '', '', 'a.@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', 'viewtopic.php', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', 'j', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', 'ST', '', '', '@@', '', '@@', '@@', '', '', '@@', 'ite', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', 'Ma@@', '', 'DLL', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '37@@', '', '', '', '', '', '@@', '', '2,@@', '1988', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', 'Mar', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', 'ch', '', '@@', '@@', '@@', '', '', '@@', 'Distr', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '', 'Al@@', '', '', '7,@@', 'ent', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', 'from', '', '', '@@', 'page', '@@', '@@', '', '', 'GMT', '@@', '', '@@', '', 'July', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', 'ate', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '1.1', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '900', '', '', '', '', '', '', '', '@@', '', '35@@', '', '', '', '', '', '109', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', 'all@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', 'Su@@', '', '@@', 'con@@', '@@', 'C.', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '8,@@', '', '105', '', '', '', '', 'Re', '@@', '34@@', '5.', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', 'Ar@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', 'January', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '', 'Hotel', 'SR.@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '250', 'Qu@@', '', 'VIII', '', '@@', 'C.5', '@@', '', '', '', '@@', 'Views', '', '', '', '@@', '@@', '', '', '', '', '', '', 'sk@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', 'U', '', '', '', '', 'RA@@', '', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', 'F.@@', '', '@@', '@@', '', '@@', '@@', '', '', 'Apr', '', '', '', '', '@@', '', '', '', '3,@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '110', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', 'La', '', '@@', '', '@@', '@@', '', '', '', '', 'Here', '@@', '@@', '', '', '', '@@', 'ok@@', '@@', '', '', 'our@@', 'CA@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '212', '', '', '', '', '', '', 'qu@@', '@@', '@@', '@@', '', '@@', '', '@@', '', 'This', '', 's.@@', '@@', '', '@@', 'Fri', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', 'March', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', 'for@@', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', 'Are', '@@', '@@', '@@', '9,@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '}', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', 'su@@', '', '', 'index.php', '@@', '', '{', '', 'be@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', 'ht@@', 'est@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', 'por@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', 'href', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', 'ist@@', '', '@@', '@@', '@@', 'te', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', 'RE@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', 'Unknown', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', 'ents', '@@', '', '@@', '', '', '@@', '', '', '@@', '', 'encounter', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', 'An@@', '', '', '', '@@', '@@', '', 'os', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '2.2', 'XX@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', 'no@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', 'tel', '@@', '', '@@', '', 'ph@@', '', '', 'ho@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', 'Con@@', '', '@@', '@@', '@@', '@@', 'Wed', '@@', '', '@@', '@@', '', '@@', 't.@@', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '@@', 'ers', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', 'iv', '@@', '', '', '', '', '', '', '@@', '', '6.', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', 'ment', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', 'Corr.1', '', '', '@@', '', '@@', '@@', '', '', '', '@@', 'Ex@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', 'ob@@', '', '', '36@@', '@@', '@@', '', 'au@@', '@@', '', '@@', '', '', 'Mon@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '11@@', '', '@@', '', '', 'Log', '', '', '', '@@', '@@', '', '', '', '@@', '.48', 'me@@', 'Sat', '@@', '', '', '', '@@', 'ai@@', '@@', '22@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', 'CDATA', '@@', '', '@@', '', '', '', 'iz@@', '', '', '@@', '', '1.2', '@@', '@@', '3.1', '@@', '.ua', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '101', '@@', '@@', '', '@@', '', '@@', '', 'wor@@', 'DA@@', '', '@@', '', '@@', '@@', 'gr@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', 'ly', '@@', '', 'April', '', '', '', '', '', '@@', '', '@@', '', 'ub@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', 'CR@@', '', '@@', '@@', 'Sun', '', '@@', '', '@@', '', 'tem@@', '', '@@', 'ik@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', 'ati@@', '', '', '@@', '', '', '', '', '', '', '@@', 'tremulous.net', '@@', 'one', '@@', '', '', '', '', 'February', '@@', '@@', '@@', '', '@@', '', '', 'you', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', 'ate@@', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '', '', 'oo@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '0.@@', '@@', '', '', '', '', '@@', 'Aug', '', '@@', '', '', '', '.', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '38@@', '', 'ID', '', 'B.@@', '', '', '', '', '@@', '', '', '@@', '', '', 'be', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', 'PR@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', 'sm@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', 'Page', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '', 'Y', '', '@@', '@@', '', 'Sep', '', '', '@@', '@@', '', '', '.', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '', 'ter@@', '', '', '', '', '@@', '@@', '', '@@', '.', 'Mon', '@@', '', 'id', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', 'V.', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', 'ess', '@@', 'do@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', 'Jan', '', '', '', '', '@@', '', '@@', 'log@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', 'view', '', '', '@@', 'En@@', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', 'Jul', '', '@@', '', 'ep@@', '@@', '102', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', 'El', 'Sh@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '130', '', 'af@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', 'se', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '@@', 'art@@', '@@', '', 'all', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '49@@', '@@', '', 'ay', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', ',5', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '@@', 'ic', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', 'Tran@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '104', '', '@@', '', 'private', '1986', '@@', '', '', '', '@@', '', 'IX', '', '', '7.', 'Jun', '@@', '@@', '', '', '@@', '', '@@', '', '', '', 'ev@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '39@@', '', '@@', '', '45@@', '', '', '103', '@@', '@@', '', '', '', '', '', '', '', 'message', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', 'bi@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '55@@', '@@', 'gallery', '', '', 'age@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', 'amp', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '..', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', 'Send', '', '@@', '', '1980', '', '@@', '', '', '', '', 'ie', '', 'Oct', '@@', 'ric@@', 'site', '', '', 'Go', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '111', 'RC', 'th', '@@', '@@', '', '', '3.2', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '106', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', 'Par@@', '', '', '@@', '', '', '', 'Tue', 'ang@@', '', '@@', '', '', '', '@@', '@@', '', '112', '@@', '', '', '', '.com@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', 'ail@@', '', '', '47@@', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '160', '', '', '', '', '@@', '180', '.dll', '@@', 'ard', '@@', '108', 'ally', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', 'pdf', '', '', '', '@@', '@@', '', '@@', '@@', '1000', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', 'ain@@', '', '@@', '', '@@', '', '@@', 'Col@@', '', '', '@@', 'e.com', '', '@@', '@@', '', '', '', '', 'actual', '', '', '', '', '@@', '@@', 'Mar@@', '', '@@', 'Feb', '', '@@', '@@', '', '', '', '', '', 'Pl@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '107', '', 'hora', '', '@@', '', '140', '48@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '', '', 'huso', 'horario', 'ro', '', 'For@@', '', '.php', '', '@@', 'ys@@', '@@', '', '@@', '', '1985', '@@', 'number', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', 'CON@@', '1987', '@@', '', '', '', 'Location', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', 're', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', 'bl@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '', 'ow@@', '', '', '', '', '', '', '', '', '', '', '@@', '77@@', '', '', '', '@@', '', '', 'ile', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', 'll@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', 'to@@', '', '@@', '@@', '@@', '', 'ity', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', 'Lin@@', '', '@@', '@@', '@@', '@@', '46@@', '', '@@', '', '', '2.2.@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', 'ote', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', 'ci@@', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '8.', '', '', 'how', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '115', 'ID@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '.@@', '', 'est', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', 'um', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '.@@', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '@@', '@@', '', 'back', '', '', '', '@@', '', '', '', '@@', '', '', '', '56@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', 'Sp@@', '@@', '', '@@', '@@', '', '', 'ff@@', '@@', '', '', '', '1982', '@@', 'very', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '86@@', '', '', '@@', '', '@@', '', '', '', '@@', '', 'many', '', '', '@@', '@@', 'Nov', '@@', '@@', '@@', '', '@@', '@@', '', '', '', 'og@@', '', '', '', '', '@@', '@@', '', '', '', '', '', 'res@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '57@@', '@@', 'gam@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '@@', 'EP', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', 'aps', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '', 'cd@@', '@@', '@@', '', 'topic', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', 'II@@', '', '@@', '@@', '2020', '', '1967', '', '', '', '@@', '', '@@', '@@', '', '@@', 'pos@@', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', 've@@', '', '', '', '', '', 'ill@@', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '', 'Thu', '01.@@', '@@', '', '@@', '', '@@', 'SP', '', '@@', '', '', '', '', '', '@@', 'lin@@', 'ni@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', 'out', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', 'upd@@', '@@', '', '@@', '', '@@', '.', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '43@@', 'AR@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', 'ww@@', '', '@@', '', '@@', '', 'Dec', '', 'He@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', 'il', '', '113', '', '', '', '@@', '', '', '', '', '', '.', '', '', '@@', '@@', '', '', '@@', '125', '116', '@@', '@@', '@@', '@@', 'ages', '@@', 'cal@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '87@@', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '', 'ice', '', '4.1', '@@', '', '@@', 'Mach@@', '.3', '@@', '', '', '@@', '', '@@', 'ina', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '@@', 'Serv@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', 'Pos@@', '', '', '', '', '123', '', '@@', '', '', '', '@@', '', '', 'HRC', 'fil@@', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '114', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', 've', 'OS', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '59@@', '@@', '', '', 'AS@@', '', '@@', '117', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '', 'we@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '@@', 'ian', '', '', '@@', '@@', '', '', '.@@', '@@', '', '@@', '@@', '', '@@', '', 'q@@', '@@', '@@', '', '@@', '', '', '', '@@', '', 'CD', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '.', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '122', '', '', 'jpg', '', 'ell@@', '', '', '', '', '', '', 'tes', '', '', '', '', '@@', 'ge', '', '', '1,5', '', '@@', '', '', '', '@@', '@@', '@@', '.', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', 'cl@@', '@@', '', '@@', '', '', 'ount', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '118', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '.', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', 'Pre@@', '@@', 'eli@@', '', '', '@@', '', '', 'cra@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '@@', 'urs@@', '', '@@', '', '', '', '@@', 'dis@@', '', '', '@@', '', '', '', 'arm@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', 'ran@@', '66@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '@@', 'Cl@@', 'eng@@', '', '@@', '@@', '@@', '@@', 'vo@@', '@@', '', '@@', 'led', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', 'son@@', '', '', '', '', 'age', '', '', '@@', '', '', '@@', '@@', '@@', '', 'edn@@', '', '', '@@', '', 'info', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '119', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', 'IM@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', 'ome', '', '44@@', '', '06.@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', 'fe@@', '@@', '', 'A.@@', '', '', '@@', '', 'la', '', '', '@@', '', 'actu@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', 'of@@', '', '@@', '@@', 'me', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', 'IP', '', '', 'bu@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', 'Ap@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', 'Q', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', 'esday', 'ud@@', 'par@@', '', '', '', '', '@@', '', '', 'min@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', 'comm@@', '', '', '', '', '', 'com@@', '@@', '', '@@', '121', 'www.m@@', '@@', '', '@@', '', '', '', '', '@@', '', 'Tuesday', '', '@@', '', '', 'Ad@@', '', '', '', '@@', '', '', '@@', '', '', '', '', 'ant', '', '21.@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '02.@@', '', '@@', '@@', '@@', '', '', '@@', '', '', 'NO@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '89@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '04.@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '128', '', '@@', '@@', '', '', '', 'ML', '@@', '', '', '@@', '@@', '', '', '', '', 'MA@@', '1984', '', '', '', '', 'AN@@', '', '', '@@', '', '', '@@', '', '', '', '', 'Li@@', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', 'ings', '@@', '', '', '', '', 'fe', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '1978', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', 'HT@@', '', '', '', '', '', 'Me@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', 'als', '@@', '', '@@', '', '', 'posts', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', 'ail', '', '@@', '@@', '@@', 'AT@@', '', '@@', '', '@@', '', '@@', '', '', 'Sub@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', 'Ac@@', 'news', '', 'he@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', 'ce', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', 'der', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '124', '', '@@', 'ating', '@@', '', '', '', '', '', '', '', '@@', '', '', '1981', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', 'Res@@', '', '@@', '@@', 'Fri@@', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '....', '', 'ast', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', 'ist', '', '', '', '@@', '', 'game', '', '@@', '', '@@', '', '', 'Google', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '', 'ame', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', 'net', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '2', '@@', '', '@@', '', '', '', '@@', 'inde@@', '', '@@', '', '', '@@', '@@', 'MS', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '', 'les', '132', '', '', '', '', '', '', '53@@', '', '', '88@@', '', '', '@@', '', '@@', '', '....@@', '@@', '', '', '', '67@@', '', '', '', '05.@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '153', '', '', '@@', '@@', '@@', '@@', '@@', '', '', 'tic@@', '', '@@', '', 'mar@@', '', '', 'bo@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '03.@@', '@@', '', '@@', '', '@@', '', '@@', '', 'ux', '@@', '@@', 'Comm@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '2,5', '', '', '', '', '@@', '', '@@', '135', '', '', '', '', '@@', '', '', '@@', '@@', '', '', 'Next', '', '@@', '@@', '09@@', '@@', '', '', '@@', '', '', 'up@@', '', '', '', '@@', '', '1970', '', '@@', '@@', '', '@@', '@@', '138', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '', 'io', '', '@@', '', '@@', '', '', 'rem@@', '', '', '', '', '', '', '', '', '', '0000', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '07@@', '', '134', '', '@@', '', 'Wor@@', '', 'ya', '@@', '', '', '', '170', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', 'gu@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '04@@', '', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', 'De@@', '', '@@', '', '', '', '@@', 'Post', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', 'a.com', '@@', '', '@@', 'sl@@', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '127', '', '@@', '', '', 'ack@@', '', '@@', '@@', 'ata', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', 'Original', '', '@@', '@@', '', '@@', '', '', '@@', '', 'ES@@', '@@', '', '', '', '', '', '', 'Z', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', 'ous@@', '', '', '', '', '', '', '126', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'PS', '@@', '', '@@', 'get', '@@', '', '', '', '@@', '', '', '@@', '', 'get@@', '', 'our', '', '', '@@', 'that', '@@', '', '@@', 'IC@@', '@@', '', 'with', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', 'gi@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', 'man@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '1973', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '15.@@', '', '', '', '', '@@', '', '', '', '', '@@', 'TRA@@', '22.@@', '', 'line', '58@@', '', 'Sk@@', '@@', '', '', 'ah@@', '@@', '', '@@', '', '@@', '', '155', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', ',@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '133', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', 'Le@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', 'EC@@', '', '145', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '220', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '', 'Di@@', '', '', '', '', '', 'ies', '@@', '', '@@', '@@', '@@', '', '', '', 'Bl@@', '', '', '@@', '', '@@', '', 'st', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', 'cont@@', '', '', '', '', '@@', '', '08@@', '', '', '@@', '', '@@', '@@', '129', '@@', '@@', '', '@@', '', '1979', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', 'Microsoft', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '131', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '', 'SP@@', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', 'US', '', '', '@@', '@@', '@@', '', '', '', '', 'play@@', '', '1983', '', '@@', 'Gr@@', '@@', '', '', '', '@@', '.', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '24.@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '210', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', 'ue', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '136', '@@', '', '', '', '', '', '', '@@', '@@', 'To@@', '', '@@', '', '', '', 'la@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', 'atur@@', '', '@@', '', '', '', '', '', '@@', '', '', '', 'CO', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', 'Tr@@', '', '240', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', 'ite@@', '@@', 'Car@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', 'Sunday', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '1975', '', '@@', '', '', '', '', '', '', '@@', '162', '@@', '', '@@', '137', '', '', '@@', '', '@@', '', '', '@@', 'ations', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '', 'have', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', 'des@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '350', '@@', '', '@@', '', '@@', '', '', '@@', 'ast@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '@@', 'ber@@', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', 'no', '@@', '@@', '', '', '', '@@', 'ook@@', '@@', '', '', 'ip@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', 'ace', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', 'PR', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '@@', 'img', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '144', '@@', '', '23.@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '.', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '.', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', 'bas@@', '', '', '', '', '@@', '152', '', '@@', '', '@@', '@@', '@@', '', '', 'its', '', '', '', '', '', '@@', 'FA@@', '', '', '@@', '', '', 'ort', '', '', '', '', '', '@@', '@@', '@@', 'tru@@', '', '@@', 'Mal@@', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', 'ds', '', '', '@@', '190', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', 'ank', '', '@@', '@@', '@@', '', '', 'Ne@@', '@@', '', '', '', '@@', '14.@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', '', 'World', '@@', '', '@@', '', '', '', '@@', '', '', '', '', 'ium', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', 'Be@@', '@@', '@@', 'can@@', '', '', 'duc@@', 'he', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '199@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', 'tu@@', '', '', '', '', '', '', '', 'No', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '', 'php', '@@', '', '@@', '', '', '@@', '', '', '', '@@', 'DV@@', '@@', '@@', '', '', '.', '25.@@', '', '', '', '@@', 'ka', '', '', '', '', '', '@@', 'Inter@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', 'IS', 'Rev@@', '', 'ain', '@@', 'do', '@@', '@@', '@@', '13.@@', '', '@@', '@@', '', '', '', '', '@@', '', '', 'ES', '', '', '', '', '', '@@', '@@', '', '', 'ee', '', '@@', '', '', 'ta', '', '', '@@', '', 'loc@@', '@@', '', '@@', 'ess@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', 'your', '', '', '@@', '@@', '', '', '@@', '', '', '', 'air', '@@', 'ost@@', '', '@@', '', '', '', '', '@@', 'tem', 'ros@@', '', '@@', '', '', '', 'We@@', '', '', '@@', 'TA', '.@@', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', 'dia', '', '', '@@', '', '@@', '', '', 'IT@@', '', 'ey', '', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '26.@@', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '', '', 'oun@@', '@@', '@@', '', '@@', '@@', '', '', 'src', '@@', '', '@@', '', '@@', '230', '', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', 'produc@@', 'ell', '', '', '', '', 'J', '', '@@', '', '', '@@', 'ase', '', '@@', '@@', '@@', '165', 'ass@@', '', '', '', '', '', '63@@', '@@', '@@', 'ax', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '', 'anc@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '', 'ure', 'sub@@', '', '', '', '154', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '1974', '', '', '@@', '@@', 'ak', '', '@@', '', '@@', '', '@@', '', '', 'strong', '', 'ot', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', 'International', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', 'https', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', 'ere', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', 'WW@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', 'TE@@', '', '', '10,@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', 'own', '@@', '@@', '@@', '', '', 'between', '', '@@', '@@', 'AM@@', '', '@@', '@@', '@@', '@@', '@@', '09.@@', 'Vie@@', '', '@@', '', '@@', '', 'art', '@@', '@@', '', '148', '', '', '', '@@', '', '', 'ry', '', '', '@@', '@@', '@@', '158', '@@', '', '@@', '', '', '', '', '', 'sc@@', 'ach@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', 'ight', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', 'health', '1977', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', 'fac@@', 'mit@@', 'can', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', 'sion', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '', 'ann@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', 'yn@@', '', '@@', '', '', '@@', '@@', '.', '', '', '', '@@', '@@', '', '', '@@', '1971', '@@', '@@', '', '', '', 'a.ru', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', 'mo@@', '', '@@', '', '', '@@', '', 'son', '', '', 'fi@@', '@@', '@@', 'atch@@', '', '', '@@', '', '@@', '', '@@', '', '', '', 'Ph@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', 'pe', '@@', '@@', '1976', 'Am@@', '17.@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '270', '', '', '@@', '', 'ks', '', '', '@@', '', '', '@@', '', '', '@@', '@@', 'Com@@', '', '@@', 'Se@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '159', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '', 'air@@', '', '', '', '', '', '', '@@', 'ech@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', 'w.@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '495', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '175', '@@', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', 'ence', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', 'aut@@', '@@', '@@', '', '', '', '', '', '@@', 'las@@', '@@', '', '', '', '', '.00', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '08.@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '', 'enc@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', 'end', '', '', 'ick', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '1960', '07.@@', '', '', '', '@@', '', '', '', '', '@@', '', '', 'que', '@@', '@@', '', '', 'rec@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', 'ons', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', 'cu@@', '@@', '', 'IP@@', 'king', '@@', 'na', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', 'vis@@', '.', '@@', 'ans', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', 'po@@', '@@', '', 'sch@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '1972', '@@', '', 'fun@@', '', '', '', '@@', '', 'room', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', 'ana', '', '', '', '@@', 'press@@', '', '@@', '', 'ash@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', 'ener@@', '', '', '', 'Wh@@', '', '@@', 'Co@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', 'aj@@', '', 'man', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', 'atch', '', '@@', 'Fin@@', 'Fi', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', 'English', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', 'one@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '.', '@@', '', '@@', '', '@@', '', '', '', '@@', '18.@@', '@@', '', '.', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', 'mon@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '.', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', 'dll', '', 'Fr@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', 'ant@@', '@@', '@@', '', '@@', '', '', '@@', 'go@@', '@@', '@@', '@@', '@@', '', '', '.01.@@', '', '', '', 'ek@@', '@@', '', '', '@@', '', 'amp@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '0,5', '@@', '', '@@', '260', '', '@@', '2018', '@@', '', '', '@@', '', '@@', '@@', '', 'OR@@', '', '', '', '@@', '@@', '', '@@', '', '', '', 'ur', '', '', '', '@@', '@@', '', '@@', 'R.@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', 'ory', '@@', '@@', '@@', '', '', '', '19.@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', 'ty', 'Cor@@', '', 'ex', '', '', '', '', '@@', '', '', '', 'au', '@@', '@@', 'rin@@', 'able', '', '@@', 'leg@@', '@@', '@@', '', 'FI@@', '@@', '@@', '@@', '', 'gre@@', 'hi@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', 'Comp@@', '@@', '', '@@', '', '', '', '@@', 'pri@@', '@@', '', '450', '@@', '@@', '@@', 'ion', '', '', '', '', '', '', 'cri@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '1,2', '', '', '@@', 'Group', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '', 'ree', '', '', '@@', '@@', '', '@@', '', 'pre@@', '', '', '', '', 'Rep@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', 'Gu@@', '', '', '', '', '', '@@', '.net', '', '', '', '@@', '', '@@', '', '', '', '', '@@', 'tion@@', '@@', '', '', '', '@@', '', '', '', '16.@@', '', '@@', '', '', '', '@@', 'ats', '', '', '@@', 'uc@@', '', '', '@@', '', '', '@@', '', '', 'iPhone', '@@', '@@', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '', 'res', '', 'land', '', '@@', '', 'wh@@', '@@', '@@', '@@', 'New', '@@', '', '', '@@', '12,@@', '', 'IA', '', '@@', '', '', '@@', 'ance', '', 'str@@', '', 'ol', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', 'ica', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', 'ous', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', 'fin@@', '', '', '', '', 'un', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '225', '', '', '@@', '', '', '', '@@', 'ie@@', '', '', 'Im@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '', 'www.k@@', '@@', '@@', '@@', '', 'br@@', '', 'Euro@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', 'Nor@@', '', '@@', '', '', '@@', 'SS@@', '', '', 'Au@@', 'ook', '', 'enti@@', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '1968', 'ack', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '', 'era', '@@', '', '', '', '@@', '@@', '', 'IT', '', '@@', '@@', '@@', '', '', '', '@@', 'Br@@', 'ices', '', '', '', '', '', '@@', '@@', '', '', 'will', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', 'erg@@', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '', '.@@', '@@', '@@', 'od', '', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', 'up', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', 'ong', '@@', '', '', '', 'ws', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '@@', 'Vi@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '360', '', 'out@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', 'q', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', 'ard@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '280', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', 'ary', '@@', '@@', '', 'online', '@@', '@@', '3,5', 'ore', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '.06.@@', 'heal@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', 'uk@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', 'has', '20.@@', '', '', '@@', '@@', '', '', 'ai', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', 'ect', 'Gal@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', 'ub', '@@', '@@', 'port', '', '', '@@', '@@', '@@', '@@', 'El@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', 'so', '@@', '@@', '', '@@', '', '@@', '', 'ype', '@@', 'Te@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '', 'cer@@', '', '@@', '@@', '@@', '@@', 'ade', '', '', '@@', '', '@@', '@@', '', '', 'ood', '@@', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', 'ars', '@@', '', '', '@@', '', '', '', 'ys', '', 'Mo@@', '', 'Manag@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', 'ser@@', '', '@@', '', 'ale', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', 'go', '@@', '@@', '@@', '@@', 'di', '@@', 'At@@', '@@', '', '', '@@', '@@', '@@', '@@', '', 'Gre@@', '@@', '@@', 'oin@@', '', '', '', 'ron@@', '', 'Bo@@', '@@', '', '@@', '@@', '@@', 'form@@', '', '@@', 'ject', '.', '@@', '', '', '', '@@', '', 'curr@@', '', 'Or@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '3000', 'NE@@', 'Ag@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', 'Russian', '', '@@', 'alt', '@@', 'ge@@', 'my', '@@', '@@', '@@', '', '@@', '', 'inter@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', 'Ho@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '1,3', '', '', '', 'Bar@@', 'XX', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '.@@', '@@', '@@', '', 'Fi@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '13,@@', '', 'CD@@', '@@', '@@', 'Uni@@', 'tim@@', '', 'Dec@@', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', 'gl@@', '@@', '@@', 'ls', '@@', 'Per@@', '', '', '', '', 'ond@@', '', '', '', '@@', '', '', '~', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', 'CN@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', 'und@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '.@@', '@@', '', '', '', '', '@@', '', '', 'Gener@@', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', 'Wi', '', '@@', '', '@@', '', '', '', 'ish@@', '', '', '', '', '', 'ens', '', '', '', 'Min@@', '', '', '', '', '', '@@', '', '@@', '@@', 'ation@@', '@@', 'Pol@@', '', '', '@@', '', '', '', '', 'wom@@', '', '', '', '@@', 'oor', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', 'ties', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', 'Win@@', '', '----@@', '', '', '@@', '', '', '', '', '', 'Tim@@', '', '', '@@', '@@', 'val@@', '@@', '@@', '@@', '@@', '', '', 'fl@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', 'United', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', 'fer@@', 'Sch@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', 'ish', '@@', 'ove', 'ens@@', '.', '@@', 'ern@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', 'Un@@', '', '', '@@', '', '', '', '', '0,7', '@@', '.04.@@', '@@', '', '@@', 'iti@@', 'Press', '', '', '@@', '5000', '', '', '', '@@', '@@', '', '@@', '', '.', '', '@@', '@@', '', '', '', '@@', 'Sec@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '', 'om', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', 'iv@@', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', 'ax@@', '@@', '', '@@', 'ach', '', 'ick@@', '@@', '', '', '', 'Vis@@', '', '', '@@', '', '@@', 'ash', 'per', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', 'olog@@', '', '', '', '', '', '', '', '', '', 'we', '', '@@', '', '', '--@@', 'co', '@@', '@@', '', '750', '', '', '15,@@', '@@', '', 'cel@@', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', 'Sol@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', 'ton', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', 'old', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', 'UR@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', 'gov@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', 'Tur@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '.', '', 'Op@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '@@', 'ut', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', 'Ste@@', '', '@@', 'top', 'pr@@', '', '14,@@', '', '@@', 'Fl@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '', 'ug@@', '', '', '@@', 'ake', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', 'XIX', '@@', '', '', '@@', '', '', '', '', 'old@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', 'ele@@', '', '@@', 'ws@@', '', '', '@@', '@@', 'tal@@', '@@', '', '', '@@', '', 'Cent@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '1,6', '@@', '', 'ights', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', 'ym@@', '', '', '@@', '@@', '', '', '1,4', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', 'been', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', 'ement', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '.', '@@', 'g.@@', '@@', '@@', '', '', '', '320', '', '@@', '@@', 'du@@', '0,1', '', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', 'cre@@', '@@', '@@', '', '', '', 'ft', '@@', '', '@@', '@@', '', '', '', '', 'ates', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', 'ouse', '', '', '@@', 'ads', '@@', 'Si@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', 'Em@@', '@@', '', '', '', '', 'Ltd', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '1500', '', '', '', '290', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '', 'acc@@', '', '', 'sti@@', '@@', '', '@@', '', '', '', '', '', '', 'Russia', '', '@@', '', '', '@@', 'AL', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', 'ill', '@@', '@@', '', '4,5', '', '', '', '', 'Pri@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', 'Ro@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '.@@', '', '', '', '', '', '@@', 'ne', '@@', '@@', '', '@@', '', '', '@@', '@@', '', 'last', '@@', '', '', '', '@@', '', 'ven@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', 'car@@', '', '', '', 'ps', '', '', '', '', '', '', 'sec@@', '', '@@', '', '', 'ada', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', 'ath@@', '', 'bre@@', '', '@@', '', 'IB@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', 'way', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '1,8', '', '', '', 'ater@@', '', '', 'border', '@@', '', '', 'aw@@', '@@', '', 'tions', '', '@@', '', 'pol@@', '@@', '', 'see', '@@', '', 'Bank', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', '', 'new', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', 'lash', '', '.', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', 'ture', '', '', 'ste@@', '', '@@', 'ang', '.', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', 'Dev@@', '', '@@', '@@', '@@', '', '', '@@', '', '1,1', '', '', 'inf@@', '', '@@', '@@', '', '', '@@', '', 'tran@@', '', '', '', 'press', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '', 'ver', '', '', '', '', 'ow', '', '@@', '', 'wi@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '0,2', '@@', 'da', '', '@@', '', '', '', 'No@@', '', '', '@@', '', '', '@@', '', '', '', '.', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', 'ir', '@@', '@@', '', '@@', '', '', 'll', '', '', '@@', '', '', '', '', '@@', 'off@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '3D', 'TV', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '16,@@', '', '', '', 'tw@@', '@@', '', '@@', '', '@@', '', '', 'ors', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '1,7', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', 'any', '', '@@', '@@', '', '', '', '@@', '', '', 'FC', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', 'if', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', 'if@@', '', 'com', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '1950', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', 'We', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', 'ial', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '', 'In', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', 'elop@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', 'ip', '', '@@', '', '', 'Man@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '........@@', '', '@@', '', '', '', '', '@@', '20,@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '@@', 'other', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', 'DA', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', 'cor@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', 'iss@@', '', '17,@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', 'ear@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', 'hel@@', '', '', '@@', '', '', '', '', 'Inst@@', '', '@@', '@@', '', '', '', '@@', '18,@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '@@', 'org@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', 'ORIGINAL', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', 'ange', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '1945', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', 'ther', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', 'war@@', 'ters', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', 'sw@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', 'work', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', 'Ge@@', '', '@@', '@@', '', '@@', 'after', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '@@', 'Air@@', '', '', 'iP@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', 'about', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', 'AP', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', 'Cre@@', 'ye@@', '', 'don', '', '', '', 'tur@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', 'ets', '', '', 'usiness', '', 'use', 'att@@', '@@', '', '@@', '', '.', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', 'ting', '@@', '', '', '@@', '@@', '@@', '', '', 'more', '', '', '@@', '', '', '@@', '', '', '', '', '@@', 'As@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', 'ke@@', '@@', 'azazazazazazazaz@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', 'ublic', '', '', '', '', '', '@@', '@@', 'but', '@@', 'Por@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '2.0', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', 'win@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', 'ner', 'WA@@', '', '', '', '', '', '', '', 'app@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '19,@@', '', '', '@@', '@@', '', '@@', '', '', 'comp@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', 'ays', '', '', '@@', '', '@@', '@@', '&#@@', '@@', '@@', '', '', 'ster@@', '', '', 'Ri@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '2,2', 'ese', '', '', '', '', 'Dis@@', '@@', '', '', '', '', '@@', 'serv@@', '@@', '@@', '', '', 'ost', '', '@@', '@@', '', 'sid@@', 'ose', '@@', '', '', '@@', '', '', '0,3', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', 'ave', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', 'sel@@', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', 'are@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', 'ool', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '', 'tri@@', '@@', '@@', '@@', '', '', '@@', '198@@', '', '', '@@', '', '', '@@', 'ding', '@@', '', '.@@', '', '@@', 'ek', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', 'bur@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '2,4', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', 'Life', '', '', '', '', '@@', '', 'pd@@', '@@', '', '', '@@', '@@', '', '', '@@', 'ire', 'world', '', '@@', 'Jo@@', '', '', '@@', '', '.', 'ult', '', '', '', '', '@@', '@@', '1,9', 'ern', '', 'Mic@@', '@@', '@@', '', '2,3', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', 'Son@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', 'Mer@@', '', '', '@@', '', 'rel@@', '', '@@', '', '', '', '@@', '', 'ou', '', '', '', '@@', '@@', '@@', '', '@@', '@@', 'cent@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', 'like', '', '', '', '', '', '', '@@', 'ild@@', '@@', 'agr@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', 'ussi@@', '', '', '', '', '', '@@', '@@', 'Facebook', 'index@@', '', '', '', '', '', '', '.', 'Apple', '@@', '', '@@', '', '@@', 'Pe@@', '', '@@', '', '', '@@', '', '', '', '', '', '2,6', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', 'ical', '@@', '@@', '@@', '', 'ery', '@@', 'MT', '@@', '', '', '', '@@', '', 'tic', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '7,5', '', '', '@@', '@@', '.b@@', '@@', '@@', '@@', '2,7', 'Android', 'News', '@@', '', '', '', '@@', '', 'ble', '', '', '2030', '', '', '', '@@', 'ull', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '.', 'IG@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', 'ber', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', 'wn', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', 'ound', '@@', '@@', 'err@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', 'ke', '@@', '', '', '@@', '', '@@', '', '@@', 'tor', '', 'tiv@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', 'BA', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', 'vie@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '2,8', 'div', '', '', '', '', '', '@@', '', '', '@@', '3,2', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '0,8', '', '', '', '', '', '', '', '@@', '197@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '', 'tle', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', 'tive', '', '', '', '@@', '', '', '', '', '.', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '3,3', '', '', '@@', '', '@@', '', '', '', 'BC', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '0,4', '@@', '', '@@', '', '@@', '', '@@', '', 'www.s@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '5,5', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '@@', 'ht', '', '', '', '@@', '', '@@', '@@', 'ood@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '', '', '@@', 'NS', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '', 'Bre@@', '@@', '@@', '', '', '', '@@', '', '', 'ign', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '6,5', '@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '3,6', '2,1', '', '@@', '@@', 'Amer@@', '@@', 'the@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', 'rig@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', 'Online', '@@', '', '', '', '0,6', '@@', '', '@@', '', '@@', '', 'York', '', '', '', '@@', '@@', '', '', '', 'cur@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', 'ond', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '.u@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', 'vers@@', '@@', '', '@@', '', '', '^', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '3,4', '@@', '@@', '', '', '', '@@', 'ise', '@@', '@@', '@@', '', '', '', '', '@@', '2019', '@@', '', '@@', 'amil@@', '@@', '@@', '', '', '', '', '', 'bor@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', 'Hol@@', 'ENGLISH', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '', 'cap@@', 'ung', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', 'xt', '@@', '@@', 'Hy@@', '', '@@', '', '', '', 'And@@', '', '', '@@', '', 'ome@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', 'ative', '@@', '', 'ight@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '3,7', '', '', 'stri@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', 'ox', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', 'ress', '@@', '@@', 'port@@', 'what', '', '', '', '2,9', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', 'Inv@@', '', '', '', '@@', 'there', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '.@@', '@@', '@@', 'yright', '', '', '', '', '', '', '@@', '', '', '', '', '', 'Mus@@', 'ms', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', 'Vol@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', 'ning', '', 'ust', '@@', '', '@@', '', '', '@@', '', '@@', '', '3,8', '', '', '', '', '', '', '@@', '', '@@', 'uro@@', '', '', '@@', 'red', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '@@', '@@', 'ink', '@@', '', 'low', '', '@@', '', '', '@@', '', '@@', '@@', 'come', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '@@', 'Nov@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', 'Ke@@', '', '', '', '@@', '', '', '5,6', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '', 'thing', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', 'pres@@', '', '', '', '', '@@', '', '@@', '', '', '', '', 'Bri@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '', '', 'first', '', '', '', 'play', '', '', '', '@@', '', '', '', '@@', 'just', '', '@@', 'well', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', 'low@@', '', '', '@@', '', '4,2', '', '', '', '', '@@', '@@', '', '@@', 'pic@@', '', '@@', '@@', '', '@@', '@@', '4,6', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '', '', '', '', 'BS', '@@', 'Global', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', 'only', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', 'Her@@', '@@', '@@', '@@', '@@', 'Ju@@', '@@', 'article', '@@', '', '', '', '@@', '@@', '', 'LL', '', '', '@@', '@@', '', '@@', '@@', '', '@@', 'Keeper', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '', 'Flash', '', '', '@@', '', '@@', '', '', '', 'une', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', 'ich', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', 'ari', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', 'her', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '', '@@', '', 'had', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', 'Ben@@', '@@', '', 'Fran@@', '@@', '', '@@', 'erv@@', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '@@', 'Fe@@', 'ley', '', '', '@@', '', '', '@@', 'France', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', 'people', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', 'Lyrics', '', '@@', '', '', '', '@@', 'Air', 'let', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '8,5', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', 'iPad', '.co@@', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', 'Goo@@', 'ild', '', '', '', '@@', '', 'right', 'would', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '@@', 'ful', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '', 'also', '', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '@@', 'artic@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', 'berg', 'ario', '', '', '.@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', 'incl@@', '', '', 'One', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', 'inal', '@@', '@@', '', '@@', '', '@@', '', 'earch', '', '', '', '', '@@', '@@', '', '', '', '@@', '', 'tis@@', '', '', '@@', '', '', '@@', 'ourn@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', 'over', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', 'WS@@', '', '', '@@', '', '', '', '', '', '', '', '2025', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', 'Open', '@@', '', 'On@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', 'illi@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '', 'Samsung', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', 'GL@@', '@@', '', '', '@@', '', '@@', 'hor@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '.or@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', 'Ren@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', 'were', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', 'oom@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', 'requ@@', '', '@@', '', 'Sou@@', '@@', '', 'e', '', '', '@@', '.@@', '', '', '', '@@', '', 'oft', '', '@@', '@@', '', '@@', '', '', '@@', '@@', 'AF@@', '@@', '', 'ough', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', 'Cap@@', '@@', '', 'ep', 'they', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', 'most', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '.R@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '', 'uss@@', '@@', 'bus', '@@', '@@', '@@', '@@', '', '', '', '', '', '1941', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', 'try', '@@', '', 'coun@@', '', '', '', '@@', '', '', '', '@@', '', 'Media', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', 'spor@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', 'top@@', '.-@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', 'UK', '@@', '@@', '@@', '', 'oci@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', 'Twitter', '', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', 'Lo@@', '', '', '', '@@', '@@', '', '', '', 'off', '', '@@', '', '@@', 'where', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', 'years', '@@', '@@', '', '@@', '@@', '', '.', 'ves', '', '@@', 'when', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', 'which', '@@', '', '', '', 'Tele@@', '', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '', 'ely', '', 'ournal', '', '', '@@', '.', '', '', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', 'Loc@@', '', '@@', '', '', '', '@@', '', '@@', '@@', 'Eur@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', 'Sam@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', 'Fac@@', '', '@@', '@@', '', 'ple', '', '', '', '@@', '', '', '@@', '@@', '', '', '', 'wit@@', '', '', '', '', '', '@@', '', '', '@@', '', '', 'Sport', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '', '', 'gin', 'said', '@@', '', '@@', 'Stre@@', 'table', '', 'Street', '', 'ational', '@@', 'side', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '', 'fu@@', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', 'dec@@', '@@', '@@', 'Add@@', '@@', '', '@@', '@@', '', '@@', 'Phone', '@@', '@@', '@@', '', '', '@@', '', 'them', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', 'YouTube', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '', 'ked', '', '', '@@', 'Times', '@@', '', 'Mot@@', '', '@@', '', '@@', 'ital', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', 'city', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', 'ault', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', 'Wik@@', '@@', 'cop@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', 'Journal', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', 'bet@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', 'sci@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', 'BM@@', '', '@@', '', 'Mc@@', '', '', '@@', '', '', '', '@@', '', 'some', '', '@@', '@@', '@@', '', '', '', '', '', '', 'oug@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', 'than', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '.', '@@', '', '@@', '@@', '', '', 'ould', '', '@@', '@@', '', '@@', '', 'ington', '', '', '', '', '', '@@', 'lob@@', '@@', 'cell@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '@@', 'rom', '', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '@@', '', 'fir@@', '', '@@', '@@', '', '', '', '', '@@', '@@', 'who', '', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', 'could', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', 'lines', '@@', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', 'his', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', 'she', '@@', '', '', 'into', '@@', '', 'Sun@@', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', 'year', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '..@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', 'sport', '', '@@', '', '', '@@', '', '@@', '@@', '', 'Oc@@', '@@', '', 'national', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '.bg', '', '', '@@', 'TER@@', 'width', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '', 'soci@@', 'Micros@@', '@@', '', '', '', '@@', '', '', '@@', '', 'ube', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', 'view@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', 'Mail', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', 'Ly@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', 'ety', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', 'More', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', 'Capital', 'oot@@', 'sr@@', '@@', '', '@@', 'two', '', '', '@@', 'FA', '@@', 'But', '@@', '@@', '', '', '', '@@', '', '', '', 'Jan@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', 'space', '@@', '', '', '@@', '', '', '@@', '', '@@', 'Tu@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '@@', 'htt@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', 'sche', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', 'px', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', 'oup', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', 'ATA', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', 'You@@', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', 'RT', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', 'quo@@', '', '@@', '@@', '', '', '@@', '', 'ref', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', 'bec@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '.', '', '@@', '', '@@', '@@', '@@', '@@', '', 'ld', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', 'Associ@@', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', 'He', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', 'style', '@@', '@@', '', '', 'Windo@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', 'IPO', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', 'says', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', 'their', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '@@', '', 'yle', '@@', '@@', '', '@@', '@@', '', '@@', 'Get@@', '', '@@', '@@', '.RU', '', '@@', 'Image', '@@', '', '@@', '', '@@', '@@', '', '', '', 'gle', '@@', '@@', '', 'htm@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', 'aid', '', '', 'ota', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', 'Daily', '', '', '', '@@', '@@', '@@', '', '', 'ancial', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', 'Dist@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', 'Corr@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', 'ember', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', 'vate', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', 'ounter', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', 'KP@@', '', '@@', '', '', 'BMW', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', 'Mercedes', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', 'topic@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '.@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', 'ubli@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', 'ced@@', '@@', '', '@@', '@@', '', '', 'aks', '', '@@', '@@', 'Mr', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', 'num@@', 'jp@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', 'INTER@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', 'ently', 'Ford', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '..', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', 'roid', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', 's.net', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', 'kno@@', '@@', '', '@@', '', 'Orig@@', '', 'ISH', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '@@', 'Engl@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', 'Glob@@', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', 'ears', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '.@@', 'Toyota', '', '@@', '@@', '@@', '@@', '', '', 'BBC', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '@@', 'allery', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', 'eing', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', 'ween', '', '@@', '', '@@', '@@', 'Nissan', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', 'ardi@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '@@', 'ople', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', 'Renault', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '.', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '', 'agen', '@@', '@@', '@@', '', '', '', '@@', 'cial', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', 'nr@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', 'bes', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '', 'Audi', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '.', '', '', '', '@@', 'Boeing', '@@', '', '', '', '@@', 'Aug@@', '', '', '', '', '@@', '@@', '', '@@', 'Volkswagen', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', 'ASE', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', 'ebook', '', '@@', '@@', '', '@@', '', 'known', '@@', 'ril', 'CNN', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', 'wid@@', '@@', '@@', 'usin@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', 'mess@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', 'Reuters', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', 'trem@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', 'Guardian', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', 'hus@@', '', '', '', '', '', '', '@@', '', '', '..', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '2.ru', '', 'td', '', '@@', '@@', '@@', '@@', '@@', '', 'INAL', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', 'aily', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', 'Sep@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', 'ested', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', 'uters', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '.Ru', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '', 'aif@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', 'Russi@@', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', 'Instagram', 'Forbes', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', 'Bloomberg', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '', 'Feb@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', 'eper', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '', 'Volk@@', '', '@@', '@@', 'rics', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '0-', '@@', 'azaz@@', '', '', '@@', 'Tube', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', 'azazazaz@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', 'Toy@@', '', '@@', '', '@@', '@@', '@@', '@@', '', 'uary', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', 'society', '@@', 'agram', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', 'Yor@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', 'Telegr@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', 'viewtopic@@', '@@', '@@', '', 'apos@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '@@', 'Brent', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', 'copyright', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', 'margin', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '', 'Riot', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', 'Twit@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', 'Pussy', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', 'sung', '', '', '@@', '', '@@', 'tremul@@', '', 'tober', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '.ru.', '@@', '', '', '', '@@', 'adding', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', 'Septem@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', 'Bloom@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '', 'Niss@@', '', 'ENGL@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', 'Lent@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', 'Febru@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', 'Lada', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', 'ORIG@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', 'oined', '@@', '', '@@', '', '@@', '@@', '', 'padding', '', '', '', '@@', '', '', '@@', 'Guardi@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', 'FAX@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', 'cedes', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', 'Lenta.ru', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', 'Novin@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', 'ru.', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '@@', 'Puss@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '.Ru', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', 'tremulou@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '', 'caption', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', 'swagen', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', 'e', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '.aif.ru', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '.Ru', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', 'www.aif.ru', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '', 'INTERFAX@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '.Ru', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '@@', '@@', 'nr2.ru', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '', '', '', '', '', 'valign', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '', 'KP.RU', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', 'aif.ru', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '', '', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '', '@@', '', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '@@', '', '', '', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '', '@@', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '@@', '@@', '', '', '@@', '', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '@@', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '', '@@', '', '', '', '', '', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '@@', '', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '@@', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '@@', '@@', '', '@@', '', '@@', '@@', '', '', '', '@@', '', '', '@@', '', '@@', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '@@', '@@', '@@', '', '', '', '', '', '@@', '', '', '', '@@', '', '@@', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '', '@@', '', '@@', '@@', '@@', '', '@@', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '@@', '@@', '', '', '', '', '@@', '@@', '', '', '', '', '@@', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '', '', '', '@@', '', '@@', '', '', '@@', '', '', '', '', '@@', '@@', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '', '', '@@', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '@@', '@@', '@@', '@@', '@@', '', '@@', '', '', '@@', '@@', '@@', '', '', '', '@@', '@@', '@@', '', '', '@@', '', '@@', '', '@@', '', '', '@@', '@@', '', '', '@@', '@@', '', '', '@@', '', '', '', '', '', '', '@@', '', '@@', '', '@@', '', '', '', '@@', '@@', '@@', '@@', '', '@@', '@@', '', '@@', '', '', '@@', 'madeupword0000', 'madeupword0001', 'madeupword0002', 'madeupword0003'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_dict.indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</w>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"\\u8de8@@\"\n",
    "re.sub(r'@@', '</w>', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'le@@': 5, 'tt@@': 6, 'er': 7}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'le@@': 5, 'tt@@': 6, 'er': 7}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'le': 5, 'tt': 6, 'er</w>': 7}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = dict((re.sub(r'@@', '', k), v) if k.endswith('@@') else (re.sub(r'$', '</w>', k), v) for k, v in d.items())\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'a': 1, 'b': 2, 'c': 3}\n",
    "d2 = d1.copy()\n",
    "d2[\"a\"]=5\n",
    "ks = ['a', 'c']\n",
    "for k in ks: d2[k] = d1[k]\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8e2905a24f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"a b 3993\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a c 93939\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d k 3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmerge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerges\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'merge' is not defined"
     ]
    }
   ],
   "source": [
    "merges = [\"a b 3993\", \"a c 93939\", \"d k 3\"]\n",
    "[ a for a,b,c in merge.split()[:2] for merge in merges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "d = {'le@@': 5, 'tt@@': 6, 'er': 7}\n",
    "ks = ['le@@', 'er']\n",
    "#d1[]\n",
    "len(d)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
